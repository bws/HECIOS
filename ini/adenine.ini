# This file is shared by all PFS simulations

[General]
preload-ned-files = ../src/*/*.ned @../INET/nedfiles.lst
sim-time-limit = 2500s

network = adenine

[Cmdenv]
express-mode = yes

[Tkenv]
default-run=1

[Parameters]

###############################################################################
#
# Settings for the adenine network configuration
#
###############################################################################


###############################################################################
#
# Settings for the client/end user application
#
#   Note that in the UMD trace filename, "%r" will be replaced with the 
#   application's process rank.
#
###############################################################################
#adenine.**.mpi.app.traceFile = "/data/traces/shtf/mkdir_bm.shtf"
#adenine.**.mpi.app.traceFile = "/data/traces/shtf/file_touch_bm.shtf"
#adenine.**.mpi.app.traceFile = "/data/traces/shtf/file_write_bm.shtf"
adenine.**.mpi.app.traceFile = "/data/traces/shtf/linux_2_6_9_untar.shtf"
adenine.**.mpi.app.numTraceProcs = 1
adenine.**.mpi.IOApplicationType = "SHTFIOApplication"

###############################################################################
#
# Adenine INET component configuration
#
###############################################################################
# We should set this to something like a Foundry FESX448
adenine.switch.relayUnitType = "MACRelayUnitPP"
adenine.switch.relayUnit.addressTableFile = ""
adenine.switch.relayUnit.addressTableSize = 100000
adenine.switch.relayUnit.agingTime = 100
adenine.switch.relayUnit.processingTime = 0
adenine.switch.relayUnit.bufferSize = 65536
adenine.switch.relayUnit.highWatermark = 100000
adenine.switch.relayUnit.pauseUnits = 0
adenine.switch.relayUnit.writeScalars = false
adenine.switch.mac[*].address = "auto"
adenine.switch.mac[*].txQueueLimit = 128000
adenine.switch.mac[*].txrate = 136000000000
adenine.switch.mac[*].duplexEnabled = true
adenine.switch.mac[*].writeScalars = true

# We should set this to something like an Intel Pro/100 card
#
# RX Ring Length: 256  TX Ring Length: 128
#
adenine.**.eth[*].queueType = "DropTailQueue"
adenine.**.eth[*].queue.frameCapacity = 256
adenine.**.eth[*].mac.promiscuous = false
adenine.**.eth[*].mac.address = "auto"
adenine.**.eth[*].mac.txrate = 100000000
adenine.**.eth[*].mac.duplexEnabled = true
adenine.**.eth[*].mac.txQueueLimit = 1000
adenine.**.eth[*].mac.queueModule = ""
adenine.**.eth[*].mac.writeScalars = false
adenine.**.eth[*].encap.writeScalars = false
adenine.**.ppp[*].queueType = "DropTailQueue"
adenine.**.ppp[*].queue.frameCapacity = 0

# Various INET configuration settings
adenine.**.hca.namid = -1
adenine.**.hca.routingFile = ""
adenine.**.hca.routingFile = ""
adenine.**.hca.IPForward = 0
adenine.**.hca.networkLayer.arp.retryTimeout = 1
adenine.**.hca.networkLayer.arp.retryCount = 3
adenine.**.hca.networkLayer.arp.cacheTimeout = 100
adenine.**.hca.networkLayer.ip.procDelay = 0us
adenine.**.hca.networkLayer.proxyARP = false

###############################################################################
#
# Settings for Hard Disk drive on IONodes
#
###############################################################################
# Performance characteristics of Maxtor 5T030H3 30GB disk drive
adenine.**.hardDisk.numCylinders = 59554
adenine.**.hardDisk.numHeads = 16
adenine.**.hardDisk.numSectors = 60030432
adenine.**.hardDisk.sectorsPerTrack = 63
adenine.**.hardDisk.rpm = 7200
adenine.**.hardDisk.fixedControllerReadOverheadSecs = 0.0004
adenine.**.hardDisk.fixedControllerWriteOverheadSecs = 0.0005
adenine.**.hardDisk.trackSwitchTimeSecs = 0.001
adenine.**.hardDisk.averageReadSeekSecs = 0.0087
adenine.**.hardDisk.averageWriteSeekSecs = 0.0087

###############################################################################
#
# Settings for Operating System's storage layer
#
###############################################################################
adenine.**.storage.ioLibraryType = "ListIOLibrary"
adenine.**.storage.systemCallInterfaceType = "PassThroughSystemCallInterface"
adenine.**.storage.fileSystemType = "NativeFileSystem"
adenine.**.storage.bufferCacheType = "LRUBufferCache"
adenine.**.storage.blockTranslatorType = "BasicTranslator"
adenine.**.storage.diskSchedulerType = "FCFSDiskScheduler"
adenine.**.storage.accessManagerType = "MutexAccessManager"

# Local Node OS Settings
#
# Configure a buffer cache filling 768 MB RAM (assuming a 512 byte block size)
adenine.**.storage.bufferCache.numEntries = 1572864
#adenine.**.storage.bufferCache.numEntries = 16
adenine.**.storage.fileSystem.blockSizeBytes = 4096
adenine.**.storage.systemCall.overheadSecs = 0.0000001;

###############################################################################
#
# Parallel File System Client settings
#
###############################################################################
adenine.**.middlewareCacheType = "NoMiddlewareCache"
adenine.**.mpi.cache.dataCacheReplacePolicy = 0

###############################################################################
#
# Parallel File System Server Configuration settings
#
###############################################################################
adenine.**.fsClient.useCollectiveCreate = true
adenine.**.fsClient.useCollectiveGetAttr = false
adenine.**.fsClient.useCollectiveRemove = false
adenine.**.fsClient.directoryCreateProcessingDelaySecs = 0.001
adenine.**.fsClient.fileCloseProcessingDelaySecs = 0.0
adenine.**.fsClient.fileOpenProcessingDelaySecs = 0.0009
adenine.**.fsClient.fileReadProcessingDelaySecs = 0.0
adenine.**.fsClient.fileStatProcessingDelaySecs = 0.0
adenine.**.fsClient.fileUpdateTimeProcessingDelaySecs = 0.0
adenine.**.fsClient.fileWriteProcessingDelaySecs = 0.0

###############################################################################
#
# Parallel File System Server Configuration settings
#
###############################################################################
**.pfsConfig.metaDataSizeInBytes = 256 #ignored
**.pfsConfig.createDirEntProcessingDelaySecs = 0.00064      # Op Mean: 0.001172
**.pfsConfig.createDFileProcessingDelaySecs = 0.000354      # Op Mean: 0.000885
**.pfsConfig.createDirectoryProcessingDelaySecs = 0.001     # Op Mean: N/A
**.pfsConfig.createMetadataProcessingDelaySecs = 0.000123   # Op Mean: 0.000654
**.pfsConfig.getAttrProcessingDelaySecs = 0.000068          # Op Mean: 0.000601
**.pfsConfig.lookupPathProcessingDelaySecs = 0.000074       # Op Mean: 0.000668
**.pfsConfig.setAttrProcessingDelaySecs = 0.000352          # Op Mean: 0.001316

###############################################################################
#
# Parallel File System Server DataFlow settings
#
###############################################################################
adenine.**.clientJobManager.bufferSizeInBytes = 262144
adenine.**.clientJobManager.numBuffers = 8
adenine.**.serverJobManager.bufferSizeInBytes = 262144
adenine.**.serverJobManager.numBuffers = 8

###############################################################################
#
# Settings for BMI TCP applications
#
###############################################################################
**.ion[*].hca.tcpApp[0].listenPort = 6000
**.ion[*].hca.tcpApp[0].connectPort = 6000

# Must set the port for the BMI applications, though these will be overwritten
# when the MPI client and server are created and setup by MPIConfigurator
#
# Disable the listen functionality on the clients by setting the listen port
# to 0
**.cpun[*].hca.tcpApp[*].listenPort = 0;
**.cpun[*].hca.tcpApp[0].connectPort = 6000
**.cpun[*].hca.tcpApp[*].connectPort = 0

#
# Set the network startup costs for queue'ing and buffer copy
#  Note that none of this overhead may be overlapped on the node
#
adenine.**.tcpApp[*].fixedOverheadSecs = 0.000125
adenine.**.tcpApp[*].scaledOverheadSecs = 0.0

###############################################################################
#
# Settings for all TCP connections
#
###############################################################################
adenine.**.tcp.recordStats = 0
adenine.**.tcp.mss = 512 # bytes
adenine.**.tcp.advertisedWindow= 109568 # =64 MSSs
adenine.**.tcp.tcpAlgorithmClass="TCPReno"
adenine.**.tcp.sendQueueClass="TCPMsgBasedSendQueue"
adenine.**.tcp.receiveQueueClass="TCPMsgBasedRcvQueue"


##############################################################################
#
# UDP Applications (disabled)
#
##############################################################################
adenine.**.numUdpApps=0 # 0 means no UDP apps active.
adenine.**.udpAppType="UDPBasicApp"


##############################################################################
#
# Ping Application (disabled)
#
##############################################################################
adenine.**.pingApp.destAddr=""  # Empty destAddr ensures ping app won't start 
adenine.**.pingApp.srcAddr=""
adenine.**.pingApp.packetSize=56
adenine.**.pingApp.interval=1
adenine.**.pingApp.hopLimit=32
adenine.**.pingApp.count=0
adenine.**.pingApp.startTime=1
adenine.**.pingApp.stopTime=0
adenine.**.pingApp.printPing=false

[Run 1]
description="Run to benchmark with 1 I/O server"
adenine.numCPUNodes = 1
adenine.numIONodes = 1

[Run 2]
description="Run to benchmark with 2 I/O servers"
adenine.numCPUNodes = 1
adenine.numIONodes = 2

[Run 3]
adenine.numCPUNodes = 1
adenine.numIONodes = 3

[Run 4]
adenine.numCPUNodes = 1
adenine.numIONodes = 4

[Run 4]
adenine.numCPUNodes = 1
adenine.numIONodes = 4

[Run 5]
adenine.numCPUNodes = 1
adenine.numIONodes = 5

[Run 6]
adenine.numCPUNodes = 1
adenine.numIONodes = 6

[Run 7]
adenine.numCPUNodes = 1
adenine.numIONodes = 7

[Run 8]
adenine.numCPUNodes = 1
adenine.numIONodes = 8

[Run 16]
adenine.numCPUNodes = 1
adenine.numIONodes = 16

[Run 32]
adenine.numCPUNodes = 1
adenine.numIONodes = 32

[Run 38]
adenine.numCPUNodes = 1
adenine.numIONodes = 38

[Run 48]
adenine.numCPUNodes = 1
adenine.numIONodes = 48

[Run 64]
adenine.numCPUNodes = 1
adenine.numIONodes = 64

[Run 74]
adenine.numCPUNodes = 1
adenine.numIONodes = 74

[Run 128]
adenine.numCPUNodes = 1
adenine.numIONodes = 128
