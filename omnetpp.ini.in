#
# This file is part of Hecios
#
# Copyright (C) 2007,2008,2009 Brad Settlemyer
#
# ALL RIGHTS RESERVED.
#

#
# General Settings
#
[General]
ned-path = @INSTALL_DIR@/lib/ned
sim-time-limit = 10000s

#
# Network to enable
#
#network = PalmettoGigE
network = PalmettoMyri10G

#
# Environment settings
#
include @INSTALL_DIR@/ini/global_env.ini

#
# Output settings
#
#include @INSTALL_DIR@/ini/global_out_vectors.ini

#
# Run definitions
#
#include @INSTALL_DIR@/ini/global_run_configs.ini


#
# Enable to time ping data
#
#**.cpun[0].hca.pingApp.destAddr = "192.168.0.2"   

#
# Include parameters
#
include @INSTALL_DIR@/ini/palmetto_static_params.ini
include @INSTALL_DIR@/ini/palmetto_gige.ini
#include @INSTALL_DIR@/ini/palmetto_myri10g.ini
#include @INSTALL_DIR@/ini/palmetto_gige_doubled.ini
#include @INSTALL_DIR@/ini/palmetto_myri10g_uncapped.ini

###############################################################################
#
# Settings for the Beowulf Cluster configuration
#
###############################################################################
**.numCPUNodes = 1
**.numIONodes = 1
**.cpun[*].numProcs = 8

###############################################################################
#
# Settings for the client/end user application
#
#   Note that in the UMD trace filename, "%r" will be replaced with the 
#   application's process rank.
#
###############################################################################
**.mpiConfig.randomizeRanks = false
**.mpi.IOApplicationType = "PHTFIOApplication"
**.mpi.app.disableCPUPhase = true
**.mpi.app.isVerbose = false
**.mpi.app.traceFile = ""
#**.mpi.app.traceFile = "/data/traces/phtf/mpi-io-test_64p"
#**.mpi.app.traceFile = "/data/traces/phtf/mpi-io-test_128p"
#**.mpi.app.traceFile = "/data/traces/phtf/mpi-io-test_256p"
#**.mpi.app.traceFile = "/data/traces/phtf/flash-io_8p"
#**.mpi.app.traceFile = "/data/traces/phtf/flash-io_64p"
#**.mpi.app.traceFile = "/data/traces/phtf/flash-io_128p"
#**.mpi.app.traceFile = "/data/traces/phtf/flash-io_256p"
#**.mpi.app.traceFile = "/data/traces/phtf/flash-io_512p"
#**.mpi.app.traceFile = "/data/traces/phtf/mpi-tile-io-read_8p"
#**.mpi.app.traceFile = "/data/traces/phtf/mpi-tile-io-write_8p"

###############################################################################
#
# MPI-IO Aggregator settings
#
###############################################################################
**.mpi.middlewareAggregatorType = "NoMiddlewareAggregator"
#**.mpi.middlewareAggregatorType = "DataSievingMiddlewareAggregator"
#**.mpi.middlewareAggregatorType = "ViewAwareMiddlewareAggregator"

###############################################################################
#
# MPI-IO Cache settings
#
###############################################################################
**.mpi.middlewareCacheType = "NoMiddlewareCache"
#**.mpi.middlewareCacheType = "DirectPagedMiddlewareCache"
#**.mpi.middlewareCacheType = "PagedMiddlewareCacheMesi"
#**.mpi.middlewareCacheType = "PagedMiddlewareCacheWithTwinNoBlockIndexed"
#**.mpi.middlewareCacheType = "PagedMiddlewareCacheWithTwin"
#**.mpi.middlewareCacheType = "ProgressivePagedMiddlewareCache"
#**.mpi.middlewareCacheType = "SharedPagedMiddlewareCacheWithTwinNoBlockIndexed"
#**.mpi.middlewareCacheType = "SharedDirectPagedMiddlewareCache"
#**.mpi.middlewareCacheType = "SharedPagedMiddlewareCacheWithTwin"
#**.mpi.middlewareCacheType = "SharedProgressivePagedMiddlewareCache"
**.mpi.cache.pageCapacity = 16
**.mpi.cache.pageSize = 32768

# Note we are assuming we can copy memory at 4GB/s (a reasonable estimate)
**.mpi.cache.byteCopyTime = .00000000023283064365

###############################################################################
#
# Parallel File System Client Configuration settings
#
###############################################################################
**.fsClient.useCollectiveCreate = false
**.fsClient.useCollectiveGetAttr = false
**.fsClient.useCollectiveRemove = false
